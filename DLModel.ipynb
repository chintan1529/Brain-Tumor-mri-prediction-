{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNvFV/93ZTXxrI8Q1gDJGKw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chintan1529/Brain-Tumor-mri-prediction-/blob/main/DLModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D06mXZVY9T34",
        "outputId": "39199567-d0ed-4f40-a55a-e1bfa5a5f665"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "dataset_path = \"/content/drive/MyDrive/archive\"\n",
        "print(\"Folders inside dataset path:\", os.listdir(dataset_path))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FsZ-BSKB_YGS",
        "outputId": "313ed990-ac98-4a9c-cf67-87d747408b1d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folders inside dataset path: ['brain_tumor_dataset']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hP2G34AR8g7d",
        "outputId": "2ea9539b-b4a9-4ed4-a092-07aeeb776d10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading images from: /content/drive/MyDrive/archive/brain_tumor_dataset/yes\n",
            "Loading images from: /content/drive/MyDrive/archive/brain_tumor_dataset/no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.6767 - loss: 1.0878 - val_accuracy: 0.7059 - val_loss: 0.6388\n",
            "Epoch 2/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.7628 - loss: 0.5778 - val_accuracy: 0.7059 - val_loss: 0.5780\n",
            "Epoch 3/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.8113 - loss: 0.4681 - val_accuracy: 0.7451 - val_loss: 0.5621\n",
            "Epoch 4/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.8104 - loss: 0.4596 - val_accuracy: 0.7647 - val_loss: 0.5517\n",
            "Epoch 5/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7935 - loss: 0.4367 - val_accuracy: 0.7451 - val_loss: 0.6413\n",
            "Epoch 6/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.8357 - loss: 0.4088 - val_accuracy: 0.7451 - val_loss: 0.6084\n",
            "Epoch 7/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.8272 - loss: 0.4149 - val_accuracy: 0.7451 - val_loss: 0.5507\n",
            "Epoch 8/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.8583 - loss: 0.3379 - val_accuracy: 0.7451 - val_loss: 0.5428\n",
            "Epoch 9/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.8624 - loss: 0.2916 - val_accuracy: 0.8039 - val_loss: 0.5722\n",
            "Epoch 10/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.8917 - loss: 0.3186 - val_accuracy: 0.8431 - val_loss: 0.4590\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 215ms/step - accuracy: 0.8433 - loss: 0.4560\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 84.31%\n",
            "Model saved successfully!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Step 2: Import Required Libraries\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "# Step 3: Correct Dataset Path\n",
        "dataset_path = \"/content/drive/MyDrive/archive/brain_tumor_dataset\"\n",
        "\n",
        "# Step 4: Load and Preprocess Images\n",
        "img_size = 150  # Resize all images to 150x150\n",
        "\n",
        "def load_data(directory):\n",
        "    images = []\n",
        "    labels = []\n",
        "    class_labels = {\"yes\": 1, \"no\": 0}\n",
        "\n",
        "    for class_name, label in class_labels.items():\n",
        "        class_path = os.path.join(directory, class_name)\n",
        "        if os.path.isdir(class_path):\n",
        "            print(f\"Loading images from: {class_path}\")  # Debugging\n",
        "            for img_name in os.listdir(class_path):\n",
        "                img_path = os.path.join(class_path, img_name)\n",
        "                try:\n",
        "                    img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
        "                    img = cv2.resize(img, (img_size, img_size))\n",
        "                    images.append(img)\n",
        "                    labels.append(label)\n",
        "                except Exception as e:\n",
        "                    print(f\"Error loading image {img_path}: {e}\")\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Load dataset\n",
        "X, y = load_data(dataset_path)\n",
        "\n",
        "# Check if images loaded correctly\n",
        "if X.shape[0] == 0:\n",
        "    print(\"No images found! Check the dataset path.\")\n",
        "\n",
        "# Normalize images\n",
        "X = X / 255.0\n",
        "\n",
        "# Split data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 5: Define the CNN Model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3,3), activation='relu', input_shape=(img_size, img_size, 3)),\n",
        "    MaxPooling2D(2,2),\n",
        "\n",
        "    Conv2D(64, (3,3), activation='relu'),\n",
        "    MaxPooling2D(2,2),\n",
        "\n",
        "    Conv2D(128, (3,3), activation='relu'),\n",
        "    MaxPooling2D(2,2),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')  # Binary classification: Tumor (1) / No Tumor (0)\n",
        "])\n",
        "\n",
        "# Step 6: Compile the Model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Step 7: Train the Model\n",
        "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=32)\n",
        "\n",
        "# Step 8: Evaluate the Model\n",
        "loss, acc = model.evaluate(X_val, y_val)\n",
        "print(f\"Validation Accuracy: {acc*100:.2f}%\")\n",
        "\n",
        "# Step 9: Save Model\n",
        "model.save('/content/drive/MyDrive/brain_tumor_model.h5')\n",
        "print(\"Model saved successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit --quiet\n",
        "!pip install pyngrok --quiet\n",
        "!ngrok authtoken Your_auth_token  # Replace with your ngrok token\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjPVKHWYB6oO",
        "outputId": "6935df86-d92e-43e8-f9ee-d9bcd9718ff7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "# Load the trained model\n",
        "model = tf.keras.models.load_model('/content/drive/MyDrive/brain_tumor_model.h5')\n",
        "\n",
        "def predict_tumor(image):\n",
        "    img = cv2.resize(image, (150, 150))\n",
        "    img = img / 255.0\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    prediction = model.predict(img)[0][0]\n",
        "    result = \"Tumor Detected\" if prediction > 0.5 else \"No Tumor\"\n",
        "    return result, prediction\n",
        "\n",
        "def main():\n",
        "    st.title(\"🧠 Brain Tumor Detection\")\n",
        "    st.write(\"Upload an MRI scan, and the model will predict whether a brain tumor is present.\")\n",
        "\n",
        "    uploaded_file = st.file_uploader(\"Choose an MRI Image...\", type=[\"jpg\", \"png\", \"jpeg\"])\n",
        "\n",
        "    if uploaded_file is not None:\n",
        "        image = Image.open(uploaded_file)\n",
        "        st.image(image, caption=\"Uploaded MRI Image\", use_column_width=True)\n",
        "\n",
        "        image = np.array(image)\n",
        "        if image.shape[-1] == 4:\n",
        "            image = cv2.cvtColor(image, cv2.COLOR_RGBA2RGB)\n",
        "\n",
        "        result, score = predict_tumor(image)\n",
        "        st.write(f\"### Prediction: {result}\")\n",
        "        st.write(f\"### Confidence Score: {score:.4f}\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3PPg3I6Bozt",
        "outputId": "2716dcae-8f10-485f-c7aa-5cbd24c7ac61"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "import os\n",
        "import time\n",
        "\n",
        "# Kill any existing ngrok tunnels\n",
        "os.system(\"pkill -f ngrok\")\n",
        "\n",
        "# Start Streamlit\n",
        "os.system(\"streamlit run app.py &\")\n",
        "\n",
        "# Wait for Streamlit to start\n",
        "time.sleep(5)\n",
        "\n",
        "# Correct way to expose port 8501 using ngrok\n",
        "public_url = ngrok.connect(8501)  # No need for \"port=\"\n",
        "print(f\"🚀 Streamlit app is running at: {public_url}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OeXt6WXIDTkH",
        "outputId": "89731bf7-50e9-435b-9f42-3718ed40c5de"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 Streamlit app is running at: NgrokTunnel: \"https://be66-104-155-226-102.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    }
  ]
}